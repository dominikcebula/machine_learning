{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f aclImdb_v1.tar.gz\n",
    "!rm -Rf aclImdb\n",
    "!rm -f movie_data.csv\n",
    "!rm -f movie_data_train.csv\n",
    "!rm -f movie_data_validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-26 21:25:49--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz’\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  10.3MB/s    in 9.6s    \n",
      "\n",
      "2018-09-26 21:25:59 (8.34 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in dataset 50000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "numberOfFiles = 0\n",
    "for s in ('test', 'train'):\n",
    "    for l in ('pos', 'neg'):\n",
    "        path = './aclImdb/%s/%s' % (s, l)\n",
    "        numberOfFiles += len(os.listdir(path))\n",
    "\n",
    "print 'Number of files in dataset ' + str(numberOfFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyprind in /home/ec2-user/anaconda3/envs/python2/lib/python2.7/site-packages (2.11.2)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python2/lib/python2.7/site-packages (3.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python2/lib/python2.7/site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyprind\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:28\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pbar = pyprind.ProgBar(numberOfFiles)\n",
    "\n",
    "labels = {'pos':'1', 'neg':'0'}\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for s in ('test', 'train'):\n",
    "\tfor l in ('pos', 'neg'):\n",
    "\t\tpath ='./aclImdb/%s/%s' % (s, l)\n",
    "\t\t\n",
    "\t\tfor file in os.listdir(path):\n",
    "\t\t\twith open(os.path.join(path, file), 'r') as infile:\n",
    "\t\t\t\ttxt = infile.read()\n",
    "\t\t\t\tdf = df.append([['__label__' + labels[l], txt]], ignore_index=True)\n",
    "\t\t\tpbar.update()\n",
    "\n",
    "df.columns = ['label', 'text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv('./movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>I came out of \"Dark Blue World\" feeling (sigh)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>About five years ago, my friend and I went to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>The one sheets and newspaper campaign suggeste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>The Williams family live on a ranch located in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>This film wasn't programmed in Italian cinemas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "0  __label__1  I came out of \"Dark Blue World\" feeling (sigh)...\n",
       "1  __label__0  About five years ago, my friend and I went to ...\n",
       "2  __label__0  The one sheets and newspaper campaign suggeste...\n",
       "3  __label__1  The Williams family live on a ranch located in...\n",
       "4  __label__0  This film wasn't programmed in Italian cinemas..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./movie_data.csv')\n",
    "df_row_count = len(df.index)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "porter = PorterStemmer()\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    text = text + ''.join(emoticons).replace('-', '')\n",
    "    text = tokenizer_porter(text)\n",
    "    text = [w for w in text if w not in stop]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:07:13\n"
     ]
    }
   ],
   "source": [
    "pbar = pyprind.ProgBar(df_row_count)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'text'] = preprocessor(row['text'])\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>came dark blue world feel sigh sad yet wa defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>five year ago friend went video rental store g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>one sheet newspap campaign suggest often far l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>william famili live ranch locat middl remot de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>thi film program italian cinema seen manifest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "0  __label__1  came dark blue world feel sigh sad yet wa defi...\n",
       "1  __label__0  five year ago friend went video rental store g...\n",
       "2  __label__0  one sheet newspap campaign suggest often far l...\n",
       "3  __label__1  william famili live ranch locat middl remot de...\n",
       "4  __label__0  thi film program italian cinema seen manifest ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validation = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "train.to_csv('movie_data_train.csv', header = False, sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n",
    "validation.to_csv('movie_data_validation.csv', header = False, sep='\\t', index=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::748487307014:role/service-role/AmazonSageMaker-ExecutionRole-20180926T205031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://dc-machine-learning/sagemaker_imdb_sentiment_analysis/validation/movie_data_validation.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "bucket = 'dc-machine-learning'\n",
    "prefix = 'sagemaker_imdb_sentiment_analysis'\n",
    "\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "sess.upload_data(path='./movie_data_train.csv', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='./movie_data_validation.csv', bucket=bucket, key_prefix=validation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: blazingtext-2018-09-26-21-34-52-840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 813361260812.dkr.ecr.eu-central-1.amazonaws.com/blazingtext:latest (eu-central-1)\n",
      "2018-09-26 21:34:53 Starting - Starting the training job...\n",
      "Launching requested ML instances......\n",
      "Preparing the instances for training...\n",
      "2018-09-26 21:36:50 Downloading - Downloading input data...\n",
      "2018-09-26 21:37:05 Training - Training image download completed. Training in progress.\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[09/26/2018 21:37:12 WARNING 139882596902720] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[09/26/2018 21:37:12 WARNING 139882596902720] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[09/26/2018 21:37:12 INFO 139882596902720] nvidia-smi took: 0.0252239704132 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[09/26/2018 21:37:12 INFO 139882596902720] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[31m[09/26/2018 21:37:12 INFO 139882596902720] Processing /opt/ml/input/data/train/movie_data_train.csv . File size: 29 MB\u001b[0m\n",
      "\u001b[31m[09/26/2018 21:37:12 INFO 139882596902720] Processing /opt/ml/input/data/validation/movie_data_validation.csv . File size: 7 MB\u001b[0m\n",
      "\u001b[31mRead 5M words\u001b[0m\n",
      "\u001b[31mNumber of words:  39191\u001b[0m\n",
      "\u001b[31mLoading validation data from /opt/ml/input/data/validation/movie_data_validation.csv\u001b[0m\n",
      "\u001b[31mLoaded validation data.\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0451  Progress: 9.84%  Million Words/sec: 6.51 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0419  Progress: 16.28%  Million Words/sec: 7.15 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0388  Progress: 22.44%  Million Words/sec: 7.37 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0356  Progress: 28.83%  Million Words/sec: 7.57 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0324  Progress: 35.23%  Million Words/sec: 7.70 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0290  Progress: 41.97%  Million Words/sec: 7.85 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0264  Progress: 47.12%  Million Words/sec: 7.96 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[31mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.886\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0239  Progress: 52.22%  Million Words/sec: 7.55 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0214  Progress: 57.24%  Million Words/sec: 7.64 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[31mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.8908\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0184  Progress: 63.21%  Million Words/sec: 7.33 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0158  Progress: 68.34%  Million Words/sec: 7.43 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[31mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.8929\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0131  Progress: 73.78%  Million Words/sec: 7.25 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0105  Progress: 79.04%  Million Words/sec: 7.35 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[31mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.8941\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0076  Progress: 84.77%  Million Words/sec: 7.23 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0050  Progress: 89.95%  Million Words/sec: 7.32 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[31mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.8938\u001b[0m\n",
      "\u001b[31mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0017  Progress: 96.63%  Million Words/sec: 7.22 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[31mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.895\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 7.14 #####\u001b[0m\n",
      "\u001b[31mTraining finished.\u001b[0m\n",
      "\u001b[31mAverage throughput in Million words/sec: 7.14\u001b[0m\n",
      "\u001b[31mTotal training time in seconds: 7.33\n",
      "\u001b[0m\n",
      "\u001b[31m#train_accuracy: 0.9503\u001b[0m\n",
      "\u001b[31mNumber of train examples: 40000\n",
      "\u001b[0m\n",
      "\u001b[31m#validation_accuracy: 0.895\u001b[0m\n",
      "\u001b[31mNumber of validation examples: 10000\u001b[0m\n",
      "\n",
      "2018-09-26 21:37:25 Uploading - Uploading generated training model\n",
      "2018-09-26 21:37:41 Completed - Training job completed\n",
      "Billable seconds: 52\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print('Using SageMaker BlazingText container: {} ({})'.format(container, region_name))\n",
    "\n",
    "bt_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.m4.xlarge',\n",
    "                                         train_volume_size = 30,\n",
    "                                         train_max_run = 30,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n",
    "\n",
    "bt_model.set_hyperparameters(mode=\"supervised\",\n",
    "                            epochs=10,\n",
    "                            min_count=2,\n",
    "                            learning_rate=0.05,\n",
    "                            vector_dim=10,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=2)\n",
    "\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}\n",
    "\n",
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: blazingtext-2018-09-26-21-38-04-734\n",
      "INFO:sagemaker:Creating endpoint with name blazingtext-2018-09-26-21-34-52-840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "text_classifier = bt_model.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'love latest product updat :)', u'hate wa implement recent :(']\n",
      "[\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9930997490882874\n",
      "    ], \n",
      "    \"label\": [\n",
      "      \"__label__1\"\n",
      "    ]\n",
      "  }, \n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.8289283514022827\n",
      "    ], \n",
      "    \"label\": [\n",
      "      \"__label__0\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I love latest product update :)\",\n",
    "    \"I hate what was implemented recently :(\"\n",
    "]\n",
    "\n",
    "tokenized_sentences = [''.join(preprocessor(sent)) for sent in sentences]\n",
    "\n",
    "print(tokenized_sentences)\n",
    "\n",
    "payload = {\"instances\" : tokenized_sentences}\n",
    "\n",
    "response = text_classifier.predict(json.dumps(payload))\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python2",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
